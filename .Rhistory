}
page_urls
page_urls[1] <- base_url
page_urls
page_urls[1:10]
is.character(page_urls)
num_pages <- 476
# initialize empty vector to store all urls
page_urls <- vector("character", num_pages)
page_urls
length(page_urls)
base_url <- "https://www.presidency.ucsb.edu/documents/app-categories/presidential/letters"
# determine how many pages we need to turn
num_pages <- 476
# initialize empty vector to store all urls
page_urls <- vector("character", num_pages)
page_urls
length(page_urls)
# loop to populate with data this empty vector
for (i in 1:num_pages) {
page_urls[i] <- paste0(base_url, "?page=", i)
}
page_urls
# add at position 1 the page we already collected data from
# it has a slightly different structure
page_urls[1] <- base_url
page_urls[1:10]
# note this is a simple character vector
is.character(page_urls)
for (i in 1:num_pages) {
page_urls[i] <- paste0(base_url, "?page=", i - 1)
}
page_urls
# add at position 1 the page we already collected data from
# it has a slightly different structure
page_urls[1] <- base_url
page_urls
1:seq_along(page_urls)
page_urls
links_all_pages <- function(p) {
page <- read_html(p)  %>%
links <- page %>%
html_elements("div.field-title p a") %>%
html_attr("href")
return(links)
}
all_urls <- vector("character")
for (url in 1:seq_along(page_urls)) {  # 1:476
all_urls <- links_all_pages(page_urls[i])
}
links_all_pages <- function(p) {
page <- read_html(p)  %>%
links <- page %>%
html_elements("div.field-title p a") %>%
html_attr("href")
return(links)
}
links_all_pages(page_urls[i])
links_all_pages <- function(p) {
page <- read_html(p)
links <- page %>%
html_elements("div.field-title p a") %>%
html_attr("href")
return(links)
}
all_urls <- vector("character")
for (url in 1:seq_along(page_urls)) {  # 1:476
all_urls <- links_all_pages(page_urls[i])
}
all_urls
all_urls <- vector("character")
for (url in 1:seq_along(page_urls)) {  # 1:476
all_urls[i] <- links_all_pages(page_urls[i])
}
all_urls
all_urls <- vector("character")
all_urls
for (url in 1:seq_along(page_urls)) {
print(url)
}
for (url in 1:seq_along(page_urls)) {
print(url)
print(page_urls(url))
}
page_urls
for (url in 1:seq_along(page_urls)) {
print(url)
print(page_urls[url])
}
for (url in seq_along(page_urls)) {
print(url)
print(page_urls[url])
}
for (i in seq_along(page_urls)) {
all_urls[i] <- links_all_pages(page_urls[i])
}
# test it out with print statements
for (i in seq_along(page_urls)) {
print(i)
print(page_urls[i])
}
for (i in 1:5) {
all_urls[i] <- links_all_pages(page_urls[i])
}
all_urls
# implement for 5 urls only
for (i in 1:3) {
all_urls[i] <- links_all_pages(page_urls[i])
}
all_urls
all_urls
for (i in 1:3) {
page_links <- links_all_pages(page_urls[i])
}
page_links
for (url in page_urls[1:3]) {
page_links <- links_all_pages(url)
}
page_links
# implement for 3 urls only
for (url in page_urls[1:3]) {
print(url)
page_links[url] <- links_all_pages(url)
}
page_links
page_links <- vector("character", 10)
# implement for 3 urls only
for (url in page_urls[1:2]) {
print(url)
page_links <- links_all_pages(url)
}
page_links
for (url in page_urls[1:2]) {
print(url)
page_links[url] <- links_all_pages(url)
}
page_links
length(page_links)
for (url in page_urls[1:3]) {
print(url)
#page_links[url] <- links_all_pages(url)
}
links_all_pages(https://www.presidency.ucsb.edu/documents/app-categories/presidential/letters)
links_all_pages("https://www.presidency.ucsb.edu/documents/app-categories/presidential/letters")
links_all_pages("https://www.presidency.ucsb.edu/documents/app-categories/presidential/letters?page=2")
links_all_pages(page_urls[1])
links_all_pages(page_urls[2])
page_links <- vector("character", 10)
# implement for 3 urls only
for (url in page_urls[1:3]) {
print(url)
print(links_all_pages(page_urls[url]))
}
for (url in page_urls[1:3]) {
print(url)
print(links_all_pages(page_urls[url]))
}
for (url in page_urls[1:3]) {
print(url)
links_all_pages(page_urls[url])
}
rlang::last_trace()
for (i in seq_along(page_urls)) {
print(i)
print(page_urls[i])
}
for (i in seq_along(page_urls[1:3])) {
print(i)
print(page_urls[i])
}
for (i in seq_along(page_urls[1:3])) {
links_all_pages(page_urls[i])
}
for (i in seq_along(page_urls[1:3])) {
print(links_all_pages(page_urls[i]))
}
length(page_urls*10)
ength(page_urls)*10)
length(page_urls)*10)
length(page_urls) * 10
length(page_urls)
length(page_urls[1:3])
length(page_urls[1:3]) * 10)
length(page_urls[1:3] * 10)
length((page_urls[1:3]) * 10)
length(page_urls[1:3] * 10)
selection <- page_urls[1:3]
selection
length(selection) * 10
# now store output
selection <- page_urls[1:3]
all_urls <- vector("character", length(selection) * 10)
# Loop through page_urls and save each URL to the vector
for (i in seq_along(page_urls[1:3])) {
all_urls[i] <- links_all_pages(page_urls[i])  # Save the URL in the vector
}
all_urls
selection <- page_urls[1:3]
all_urls <- vector("character", length(selection) * 10)
all_urls
length(all_urls)
for (i in seq_along(page_urls[1:3])) {
all_urls[i] <- links_all_pages(page_urls[i])
}
all_urls
for (i in seq_along(page_urls[1:3])) {
print(links_all_pages(page_urls[i]))
}
# now store output
selection <- page_urls[1:3]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
# outer loop: Loop through the first 3 page URLs
for (i in seq_along(page_urls[1:3])) {
# get the links from the current page
page_links <- links_all_pages(page_urls[i])
# inner loop: loop through each link on the page
for (link in page_links) {
# append each link to the all_urls vector
all_urls <- c(all_urls, link)
}
}
# View the collected links
all_urls
# now store output
selection <- page_urls[1:3]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
all_urls
# outer loop: Loop through the first 3 page URLs
for (i in seq_along(page_urls[1:3])) {
# get the links from the current page
page_links <- links_all_pages(page_urls[i])
# inner loop: loop through each link on the page
for (link in page_links) {
# append each link to the all_urls vector
all_urls <- c(all_urls, link)
}
}
# View the collected links
all_urls
selection <- page_urls[1:3]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
# outer loop: Loop through the first 3 page URLs
for (i in seq_along(page_urls[1:3])) {
# get the links from the current page
page_links <- links_all_pages(page_urls[i])
page_links
# inner loop: loop through each link on the page
for (link in page_links) {
# append each link to the all_urls vector
all_urls <- c(all_urls, link)
}
}
# View the collected links
all_urls
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
# outer loop: Loop through the first 3 page URLs
for (i in seq_along(page_urls[1:2])) {
# get the links from the current page
page_links <- links_all_pages(page_urls[i])
print(page_links)
# inner loop: loop through each link on the page
for (link in page_links) {
# append each link to the all_urls vector
print(link)
all_urls <- c(all_urls, link)
}
}
# View the collected links
all_urls
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
# outer loop: Loop through the first 3 page URLs
for (i in seq_along(page_urls[1:2])) {
# get the links from the current page
page_links <- links_all_pages(page_urls[i])
page_links
# inner loop: loop through each link on the page
for (link in page_links) {
# append each link to the all_urls vector
print(link)
#all_urls <- c(all_urls, link)
}
}
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
# outer loop: Loop through the first 3 page URLs
for (i in seq_along(page_urls[1:2])) {
# get the links from the current page
page_links <- links_all_pages(page_urls[i])
page_links
}
page_links
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
# outer loop: Loop through the first 3 page URLs
for (i in seq_along(page_urls[1:2])) {
# get the links from the current page
page_links[i] <- links_all_pages(page_urls[i])
page_links
}
page_links
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
# outer loop: Loop through the first 3 page URLs
for (i in seq_along(page_urls[1:2])) {
# get the links from the current page
page_links <- links_all_pages(page_urls[i])
page_links
# inner loop: loop through each link on the page
for (link in page_links) {
# append each link to the all_urls vector
all_urls <- c(all_urls, link)
}
}
all_urls
all_urls
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
url_index <- 1
# outer loop: iterates through the selected URLs only
for (i in seq_along(page_urls[1:2])) {
# get the links from the current page
page_links <- links_all_pages(page_urls[i])
# inner loop: loop through each link on the page and stores them
for (link in page_links) {
# Append each link to the all_urls vector
all_urls[url_index] <- link
url_index <- url_index + 1  # Move to the next index
}
}
all_urls
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
url_index <- 1
# outer loop: iterates through the selected URLs only
for (i in seq_along(selection)) {
# get the links from the current page
page_links <- links_all_pages(selection[i])
page_links
# inner loop: loop through each link on the page and stores them
for (link in page_links) {
# Append each link to the all_urls vector
all_urls[url_index] <- link
url_index <- url_index + 1  # move to the next index
}
}
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
url_index <- 1
# outer loop: iterates through the selected URLs only
for (i in seq_along(selection)) {
# get the links from the current page
page_links <- links_all_pages(selection[i])
print(page_links)
# inner loop: loop through each link on the page and stores them
for (link in page_links) {
# Append each link to the all_urls vector
all_urls[url_index] <- link
url_index <- url_index + 1  # move to the next index
}
}
all_urls
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# need a nested loop!
url_index <- 1
# outer loop: iterates through the selected URLs only
for (i in seq_along(selection)) {
# get the links from the current page
page_links <- links_all_pages(selection[i])
print(page_links)
# inner loop: loop through each link on the page and stores them
for (link in page_links) {
# append each link to the all_urls vector
all_urls[url_index] <- link
url_index <- url_index + 1  # move to the next index
}
}
all_urls
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# counter
url_index <- 1
# outer loop: iterates through the selected URLs only
for (i in seq_along(selection)) {
# get the links from the current page
all_urls[url_index] <- links_all_pages(selection[i])
url_index <- url_index + 1  # move to the next index
}
all_urls
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# counter
url_index <- 1
# outer loop: iterates through the selected URLs only
for (i in seq_along(selection)) {
# get the links from the current page
all_urls[url_index] <- links_all_pages(selection[i])
url_index <- url_index + 1  # move to the next index
}
all_urls
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# counter
url_index <- 1
# outer loop: iterates through the selected URLs only
for (i in seq_along(selection)) {
# get the links from the current page
page_links <- links_all_pages(selection[i])
print(page_links)
# inner loop: loop through each link on the page and stores them
for (link in page_links) {
# append each link to the all_urls vector
all_urls[url_index] <- link
url_index <- url_index + 1  # move to the next index
}
}
all_urls
all_urls
scrape_doc <- function(url) {
# Scrapes data from US presidential pages
# Args:
# url (string): one presidential page, like "https://www.presidency.ucsb.edu/documents/special-message-the-congress-relative-space-science-and-exploration"
# Returns:
# tibble: a tibble with the date, speaker, title, full text from input url
# get HTML page
url_contents <- read_html(x = url)
# extract elements we want
date <- html_elements(x = url_contents, css = ".date-display-single") %>%
html_text2() %>% mdy()
name <- html_elements(x = url_contents, css = ".diet-title a") %>%
html_text2()
title <- html_elements(x = url_contents, css = "h1") %>%
html_text2()
text <- html_elements(x = url_contents, css = "div.field-docs-content") %>%
html_text2()
# store in a data frame and return it
url_data <- tibble(
date = date,
name = name,
title = title,
text = text
)
return(url_data)
}
scrape_doc(all_urls[1])
all_urls[1]
# now store output
selection <- page_urls[1:2]
all_urls <- vector("character", length(selection) * 10)
length(all_urls)
# counter
url_index <- 1
# outer loop: iterates through the selected URLs only
for (i in seq_along(selection)) {
# get the links from the current page
page_links <- links_all_pages(selection[i])
print(page_links)
# inner loop: loop through each link on the page and stores them
for (link in page_links) {
# append each link to the all_urls vector
all_urls[url_index] <- link
url_index <- url_index + 1  # move to the next index
}
}
all_urls
links_all_pages(page_urls[1])
links_all_pages("https://www.presidency.ucsb.edu/documents/app-categories/presidential/letters")
links_all_pages(page_urls[2])
links_all_pages("https://www.presidency.ucsb.edu/documents/app-categories/presidential/letters?page=2")
links_all_pages(page_urls[3])
links_all_pages("https://www.presidency.ucsb.edu/documents/app-categories/presidential/letters?page=2")
all_urls
